{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b71cede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Gestion des imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2412826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in d:\\python\\lib\\site-packages (2.90)\n",
      "Requirement already satisfied: pypiwin32 in d:\\python\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: comtypes in d:\\python\\lib\\site-packages (from pyttsx3) (1.1.10)\n",
      "Requirement already satisfied: pywin32 in d:\\python\\lib\\site-packages (from pyttsx3) (228)\n",
      "Requirement already satisfied: pypiwin32 in d:\\python\\lib\\site-packages (223)\n",
      "Requirement already satisfied: pywin32>=223 in d:\\python\\lib\\site-packages (from pypiwin32) (228)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3\n",
    "!pip install pypiwin32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8d1f06aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyAudio in d:\\python\\lib\\site-packages (0.2.12)\n",
      "Collecting SpeechRecognition\n",
      "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyAudio\n",
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8594d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854f6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa9f3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gestion des données\n",
    "with open(\"C:/Users/coren/Downloads/testing_dataset_1662568990.json\", encoding='utf-8') as mon_fichier:\n",
    "    data = json.load(mon_fichier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d6064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech(phrase):\n",
    "    # Python program to show\n",
    "    # Initialize the converter\n",
    "    converter = pyttsx3.init()\n",
    "\n",
    "    # Set properties before adding\n",
    "    # Things to say\n",
    "\n",
    "    # Sets speed percent \n",
    "    # Can be more than 100\n",
    "    converter.setProperty('rate', 150)\n",
    "    # Set volume 0-1\n",
    "    converter.setProperty('volume', 1)\n",
    "\n",
    "    # Queue the entered text \n",
    "    # There will be a pause between\n",
    "    # each one like a pause in \n",
    "    # a sentence\n",
    "    converter.say(phrase)\n",
    "    # Empties the say() queue\n",
    "    # Program will not continue\n",
    "    # until all speech is done talking\n",
    "    converter.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d20900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time():\n",
    "    heure = time.ctime()\n",
    "    heure = heure.split()\n",
    "    heure = heure[3]\n",
    "    heure = heure[0:5]\n",
    "    return heure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2284fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\"demande\", \"reponse\", \"heure\",\"CNAM\"] \n",
    "intention = [\"demande\", \"reponse\", \"heure\", \"cnam\"]\n",
    "phrases = []\n",
    "categorie = []\n",
    "for a in types:\n",
    "    for i in range(len(data[a])):\n",
    "            phrases.append(data[a][i][0][\"value\"])\n",
    "            categorie.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "932adc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "texte = pd.DataFrame(data =categorie,columns = [\"categorie\"])\n",
    "\n",
    "texte[\"id\"] = LabelEncoder().fit_transform(texte[\"categorie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68da5954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coren\\AppData\\Local\\Temp/ipykernel_14984/4222267409.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  texte['text'] = texte['text'].str.replace(r'[^\\w\\s]+', '')\n",
      "C:\\Users\\coren\\AppData\\Local\\Temp/ipykernel_14984/4222267409.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  stop_words['Mots'] = stop_words['Mots'].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "texte = pd.DataFrame(data =categorie,columns = [\"categorie\"])\n",
    "texte[\"id\"] = LabelEncoder().fit_transform(texte[\"categorie\"])\n",
    "texte[\"text\"] = phrases\n",
    "texte[\"text\"] = texte[\"text\"].str.lower()\n",
    "texte['text'] = texte['text'].str.replace(r'[^\\w\\s]+', '')\n",
    "texte['text'] = texte['text'].str.replace(r'_', '')\n",
    "texte['text'] = texte['text'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "stop_words = pd.read_csv(\"C:/Users/coren/Downloads/stop_words_fr.csv\")\n",
    "stop_words['Mots'] = stop_words['Mots'].str.replace(r'[^\\w\\s]+', '')\n",
    "mots = stop_words['Mots'].tolist()\n",
    "\n",
    "texte['words'] = texte[\"text\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (mots) ]))\n",
    "\n",
    "stemmer = SnowballStemmer(\"french\")\n",
    "texte['stemmed'] = texte['words'].apply(lambda x:  ' '.join([stemmer.stem(y) for y in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e4f5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 2)) \n",
    "train_matrix = cv.fit(texte['stemmed'])\n",
    "matrice = train_matrix.transform(texte['stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3002541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(matrice.toarray(), index=texte[\"id\"], columns=cv.get_feature_names())\n",
    "X = df_train.values\n",
    "Y = df_train.index\n",
    "\n",
    "lr = LogisticRegression(solver = 'liblinear')\n",
    "modele = lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0495fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_value(sentence):\n",
    "    test = pd.DataFrame([sentence], columns= [\"text\"])\n",
    "    test[\"text\"] = test[\"text\"].str.lower()\n",
    "    test['text'] = test['text'].str.replace(r'[^\\w\\s]+', '')\n",
    "    test['text'] = test['text'].str.replace(r'_', '')\n",
    "    test['text'] = test['text'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    test['words'] = test[\"text\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (mots) ]))\n",
    "    test['stemmed'] = test['words'].apply(lambda x:  ' '.join([stemmer.stem(y) for y in x.split()]))\n",
    "\n",
    "    matrice_predict = train_matrix.transform(test['stemmed'])\n",
    "    df_predict = pd.DataFrame(matrice_predict.toarray(), columns=cv.get_feature_names())\n",
    "    X_predict = df_predict.values\n",
    "    Y_predict = modele.predict(X_predict)\n",
    "    \n",
    "    return Y_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f898ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discussion(texte_a_tester):\n",
    "    reponse = predict_value(texte_a_tester)\n",
    "    if (reponse== 1):\n",
    "        speech(\"très bien merci et vous comment allez vous ?\")\n",
    "    elif (reponse==3):\n",
    "        speech(\"d'accord ça marche\")\n",
    "    elif (reponse==2):\n",
    "        speech(get_time())\n",
    "    else:\n",
    "        speech(\"je vais regarder l'emploi du temps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbd62bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coren\\AppData\\Local\\Temp/ipykernel_16672/176224154.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['text'] = test['text'].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "discussion(\"bonjour ça va ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65a1fc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrasefin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coren\\AppData\\Local\\Temp/ipykernel_16672/176224154.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['text'] = test['text'].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "speech(\"bonjour bienvenue avec Nam Bote\")\n",
    "texte_a_tester = \"\"\n",
    "while texte_a_tester != \"fin\":\n",
    "    texte_a_tester = input(\"phrase\")\n",
    "    discussion(texte_a_tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a6d3b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mappeur de sons Microsoft - Input',\n",
       " 'Microphone (Realtek(R) Audio)',\n",
       " 'Mappeur de sons Microsoft - Output',\n",
       " 'Speakers (Realtek(R) Audio)',\n",
       " 'Pilote de capture audio principal',\n",
       " 'Microphone (Realtek(R) Audio)',\n",
       " 'PÃ©riphÃ©rique audio principal',\n",
       " 'Speakers (Realtek(R) Audio)',\n",
       " 'Speakers (Realtek(R) Audio)',\n",
       " 'Microphone (Realtek(R) Audio)',\n",
       " 'Mixage stÃ©rÃ©o (Realtek HD Audio Stereo input)',\n",
       " 'Speakers 1 (Realtek HD Audio output with HAP)',\n",
       " 'Speakers 2 (Realtek HD Audio output with HAP)',\n",
       " 'Haut-parleur du PC (Realtek HD Audio output with HAP)',\n",
       " 'Microphone (Realtek HD Audio Mic input)',\n",
       " 'Casque (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free%0\\r\\n;(Aurianeâ€™s Beats StudioÂ³))',\n",
       " 'Casque (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free%0\\r\\n;(Aurianeâ€™s Beats StudioÂ³))',\n",
       " 'Casque (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free%0\\r\\n;(AirPods de Auriane))',\n",
       " 'Casque (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free%0\\r\\n;(AirPods de Auriane))',\n",
       " 'Casque ()',\n",
       " 'Casque (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free%0\\r\\n;(AirPods de corentin))',\n",
       " 'Casque (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free%0\\r\\n;(AirPods de corentin))',\n",
       " 'Casque ()',\n",
       " 'Casque ()']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83fbec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro = sr.Microphone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da0fb34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak!\n",
      "End!\n",
      "> oui bonjour comment allez-vous\n"
     ]
    }
   ],
   "source": [
    "with micro as source:\n",
    "    print(\"Speak!\")\n",
    "    audio_data = r.listen(source)\n",
    "    print(\"End!\")\n",
    "result = r.recognize_google(audio_data, language=\"fr-FR\")\n",
    "print (\">\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66778b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coren\\AppData\\Local\\Temp/ipykernel_13568/176224154.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['text'] = test['text'].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "discussion(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99c9e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk_with_nam():\n",
    "    with micro as source:\n",
    "        print(\"Speak!\")\n",
    "        audio_data = r.listen(source)\n",
    "        print(\"End!\")\n",
    "    result = r.recognize_google(audio_data, language=\"fr-FR\")\n",
    "    print (\">\", result)\n",
    "    discussion(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2efa4e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak!\n",
      "End!\n",
      "> elle t'aura ton aujourd'hui\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coren\\AppData\\Local\\Temp/ipykernel_14984/176224154.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['text'] = test['text'].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 63 features per sample; expecting 118",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14984/2546496167.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtalk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mtalk\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"fin\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtalk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtalk_with_nam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14984/3746704816.py\u001b[0m in \u001b[0;36mtalk_with_nam\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"fr-FR\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\">\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdiscussion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14984/1539551145.py\u001b[0m in \u001b[0;36mdiscussion\u001b[1;34m(texte_a_tester)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdiscussion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexte_a_tester\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mreponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexte_a_tester\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreponse\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mspeech\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"très bien merci et vous comment allez vous ?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreponse\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14984/176224154.py\u001b[0m in \u001b[0;36mpredict_value\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdf_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrice_predict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mX_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_predict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mY_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodele\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mY_predict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    289\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 63 features per sample; expecting 118"
     ]
    }
   ],
   "source": [
    "talk = \"\"\n",
    "while talk != \"fin\":\n",
    "    talk = talk_with_nam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0d9f738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrez la ville dont vous voulez connaitre la meteo en indiquant son pays : Paris,fr Londres,uk...\n",
      "De quelle ville voulez vous connaitre la meteo ? Niort\n",
      "Vous etes a Niort\n",
      "La temperature moyenne est de 15.350000000000023 degres Celsius\n",
      "Les temperatures varient entre 15.350000000000023 a 15.950000000000045 degres Celsius\n",
      "Taux d'humidite de 96%\n",
      "Conditions climatiques : few clouds\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "#récupération de la ville choisie par l'utilisateur\n",
    "print(\"Entrez la ville dont vous voulez connaitre la meteo en indiquant son pays : Paris,fr Londres,uk...\")\n",
    "ville = input(\"De quelle ville voulez vous connaitre la meteo ? \")\n",
    "\t\n",
    "#récupère le temps actuel \n",
    "url_weather = \"http://api.openweathermap.org/data/2.5/weather?q=\"+ville+\"&APPID=beb97c1ce62559bba4e81e28de8be095\"\n",
    "#url=\"http://api.openweathermap.org/data/2.5/weather?q=Londres,uk&APPID=beb97c1ce62559bba4e81e28de8be095\"\n",
    "\n",
    "r_weather = requests.get(url_weather)\n",
    "data = r_weather.json()\n",
    "#print(data)\n",
    "\n",
    "print(\"Vous etes a \" + ville)\n",
    "\n",
    "#temperature moyenne\n",
    "t = data['main']['temp']       \n",
    "print(\"La temperature moyenne est de {} degres Celsius\".format(t-273.15))\n",
    "#écart de température\n",
    "t_min = data['main']['temp_min']\n",
    "t_max = data['main']['temp_max']\n",
    "print(\"Les temperatures varient entre {}\".format(t_min-273.15) + \" a {} degres Celsius\".format(t_max-273.15))\n",
    "#taux d'humidité\n",
    "humidite = data['main']['humidity']\n",
    "print(\"Taux d'humidite de {}\".format(humidite) + \"%\")\n",
    "#état du ciel \n",
    "temps = data['weather'][0]['description']\n",
    "print(\"Conditions climatiques : {}\".format(temps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "598e7f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après soixante-dix ans d’un règne hors du commun, la souveraine laisse une empreinte durable sur la monarchie\n",
      "Tout savoir sur l’opération « London Bridge », dix jours de protocole millimétré après la mort de la souveraine\n",
      "De la seconde guerre mondiale au Brexit, une reine européenne\n",
      "« Je vous écris de Moscou » : échos clandestins de la tragédie ukrainienne\n",
      "« A1, deux corps sans vie, A3, dix corps… » : au procès de l’attentat de Nice, la description pudique et méthodique des premières constatations policières\n",
      "A Lyon, le quartier de la Guillotière pris entre l’enjeu sécuritaire et la récupération politique\n",
      "L’ex-conseiller de Trump, Steve Bannon, inculpé de fraude financière à New York\n",
      "Le commissaire aux comptes d’Arnaud Lagardère poursuivi par le régulateur\n",
      "Le chou à la crème de Mamiche, un plaisir solitaire, furtif ou délicat, dégusté ou dévoré\n",
      "Caroline Garcia balayée en demi-finales de l’US Open par Ons Jabeur\n",
      "L’élection de Jean-Christophe Lagarde au conseil municipal de Drancy encore annulée\n",
      "Mostra : avec « Blonde », plongée dans la psyché de Marilyn Monroe\n",
      "Loire et pas cher : un voyage gastronomique à Nantes\n",
      "Nantes : cinq lieux gourmands à moins de 20 euros\n",
      "Pérou : Une saison agricole secouée par la flambée des prix des engrais chimiques\n",
      "Services Le Monde\n",
      "Guides d'achat Le Monde\n",
      "Codes promo\n",
      "Le Monde à l'international\n",
      "Services Partenaires\n",
      "Sites du groupe\n",
      "Informations légales le Monde\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "  \n",
    "url = 'https://www.lemonde.fr'\n",
    "response = requests.get(url)\n",
    "  \n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "headlines = soup.find('body').find_all('h3')\n",
    "for x in headlines:\n",
    "    print(x.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87a37d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e849427e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En moins de 24 heures, deux personnes tuées par des tirs policiers à Nice et à Rennes après des refus d’obtempérer'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d8cef08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geotext\n",
      "  Downloading geotext-0.4.0-py2.py3-none-any.whl (2.0 MB)\n",
      "Installing collected packages: geotext\n",
      "Successfully installed geotext-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install geotext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de8c9a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Niort']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from geotext import GeoText\n",
    "places = GeoText(\"Quel temps fait il à Niort\")\n",
    "places.cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d3499b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
